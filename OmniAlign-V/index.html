<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference">
  <meta name="keywords" content="Human Preference Alignment, Multimodal Large Language Model, Visual Understanding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <!-- <script defer src="./static/js/fontawesome.js"></script> -->
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a> Xiangyu Zhao*</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a>Shengyuan Ding*</a><sup>2,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://zzc-1998.github.io/">Zicheng Zhang</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/hhaAndroid">Haian Huang</a><sup>2</sup>,
            </span>
            <br>
            <span class="author-block">
              <a> Maosong Cao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com.hk/citations?user=GJYzDkYAAAAJ&hl=zh-CN">Weiyun Wang</a><sup>2,4</sup>,
            </span>
            <span class="author-block">
              <a>Xinyu Fang</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://myownskyw7.github.io/">Jiaqi Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://whai362.github.io/">Wenhai Wang</a><sup>2</sup>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://faculty.sjtu.edu.cn/zhaiguangtao/zh_CN/index.htm">Guangtao Zhai</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a>Hua Yang</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://kennymckormick.github.io/">Haodong Duan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://chenkai.site/">Kai Chen</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiaotong University</span>
            <span class="author-block"><sup>2</sup>Shanghai AI Laboratory</span>
            <span class="author-block"><sup>3</sup>Nanjing University</span>
            <span class="author-block"><sup>4</sup>Fudan University</span>
            <!-- <br>
            <span class="author-block"><sup>4</sup>Zhejiang University</span>
            <span class="author-block"><sup>5</sup>Shanghai Jiao Tong University</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Paper Link. -->
              <span class="link-block">
                <a href="https://github.com/PhoenixZ810/OmniAlign-V"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/PhoenixZ810/OmniAlign-V"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/PhoenixZ/OmniAlign-V"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-download"></i>
                  </span>
                  <span>SFT Data</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/datasets/PhoenixZ/OmniAlign-V-DPO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-download"></i>
                  </span>
                  <span>DPO Data</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/open-compass/VLMEvalKit"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-key"></i>
                  </span>
                  <span>Bench</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper video. -->

<section class="hero body">
  <div class="columns is-centered has-text-centered"  style="margin-top: -50px; margin-bottom: 10px;">
    <div class="column is-three-fifths">
      <p class="title is-4">OmniAlign-V-SFT/DPO Dataset & MM-AlignBench</p>
      <!-- <h2 class="title is-3 is-centered">LGVI Framework</h2> -->
      <div class="publication-img">
        <img id="architecture" src="./static/images/teaser.png" style="width:1400px; margin-top:-10px;margin-bottom:-10px;"/>
      </div>
    </div>
  </div>
</section>


<!-- <section class="hero is-small">
  <div class="columns is-centered has-text-centered"  style="margin-top: -10px; margin-bottom: 20px;">
    <div class="column is-three-fifths">
      <div class="publication-video">
        <iframe width="200" height="180" src="https://www.youtube.com/embed/WI-65Jk0j50?si=EkA2vVDoxN8Wh3jP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
      </div>
    </div>
  </div>
</section> -->



<!-- Abstract. -->
<section class="hero is-light">
  <div class="container is-max-desktop ">
    <div class="columns is-centered has-text-centered" style="margin-top: 10px; margin-bottom: 0px;">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advancements in open-source multi-modal large language models (MLLMs) have primarily focused on enhancing foundational capabilities,
            leaving a significant gap in human preference alignment.
            This paper introduces OmniAlign-V, a comprehensive dataset of 200K high-quality training samples featuring diverse images, complex questions, and varied response formats to improve MLLMs' alignment with human preferences.
            We also present MM-AlignBench, a human-annotated benchmark specifically designed to evaluate MLLMs' alignment with human values.
            Experimental results show that finetuning MLLMs with OmniAlign-V,
            using Supervised Fine-Tuning (SFT) or Direct Preference Optimization (DPO),
            significantly enhances human preference alignment while maintaining or enhancing performance on standard VQA benchmarks, preserving their fundamental capabilities.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- /Abstract. -->

<!-- Method. -->
<section class="section" style="margin-top:-50px; margin-bottom:-50px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3 is-centered">Framework</h2>
            <div class="publication-img">
              <img id="architecture" src="./static/images/framework.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
            </div>
          </div>
        </div>
        <p>
          The pipeline of OmniAlign-V. It contains semantic-rich natural images and infographic images(Chart/Diagram/Poster). We define several tasks and for each task, we propose different methods to construct high-quality questions and images. After this, we further design post-processing refinement to enhance the quality of the dataset.
        </p>
    </div>
  </div>
</section>
<!-- Method  -->

<!-- Results -->

<!-- <section>
  <div class="container is-max-desktop" style="margin-top:-100px; margin-bottom:-50px;">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3 is-centered">Results Visualization</h2>
        </div>
      </div>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/result-comparison-both1.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/result-comparison-both2.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        MotionBooth compared with baseline models for motion-aware customized video generation.
      </h2>
    </div>
  </div>
</section> -->

<section>
  <div class="container is-max-desktop" style="margin-top:-50px; margin-bottom:-50px;">
    <div class="hero-body">      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Dataset & Benchmark</h2>
          <div class="publication-img">
            <img id="architecture" src="./static/images/statistic2.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
          </div>
        </div>
      </div>
      <h2 class="subtitle has-text-centered">
        Statistics of OmniAlign-V dataset and samples in MM-AlignBench.
      </h2>
    </div>
  </div>
</section>


<section>
  <div class="container is-max-desktop" style="margin-top:-50px; margin-bottom:-50px;">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="publication-img">
            <img id="architecture" src="./static/images/dataset_performance.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
          </div>
        </div>
      </div>
      <p>
        Our OmniAlign-V SFT dataset not only significantly improves the alignment of MLLMs with human preference, but also boosts the performance of MLLMs on common downstream tasks, particularly on benchmarks like MMVet and MMMU.
      </p>
    </div>
  </div>
</section>

<section>
  <div class="container is-max-desktop" style="margin-top:-50px; margin-bottom:-50px;">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="publication-img">
            <img id="architecture" src="./static/images/benchmark_result.png" style="width:500px; margin-top:10px;margin-bottom:10px;"/>
          </div>
        </div>
      </div>
      <p>
        Performance of existing MLLMs on MM-AlignBench. B+/B/T/W/W+ denotes MuchBetter/Better/Tie/Worse/MuchWorse.  Our LLaVA-Next-OmniAlign(OA)-32B-DPO, trained with OmniAlign-V and applied DPO with OmniAlign-V-DPO, demonstrates outstanding performance, surpassing a wide range of strong MLLMs, even Qwen2VL-72B.
      </p>
    </div>
  </div>
</section>


<section>
  <div class="container is-max-desktop" style="margin-top:-50px; margin-bottom:-50px;">
    <div class="hero-body">      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Samples</h2>
          <!-- <div class="publication-img">
            <img id="architecture" src="./static/images/datasample.png" style="width:500px; margin-top:10px;margin-bottom:10px;"/>
          </div>
          <div class="publication-img">
            <img id="architecture" src="./static/images/datasample2.png" style="width:510px; margin-top:10px;margin-bottom:10px;"/>
          </div>
          <div class="publication-img">
            <img id="architecture" src="./static/images/datasample3.png" style="width:550px; margin-top:10px;margin-bottom:10px;"/>
          </div>
          <div class="publication-img">
            <img id="architecture" src="./static/images/datasample4.png" style="width:500px; margin-top:10px;margin-bottom:10px;"/>
          </div> -->
          <div class="image-grid">
            <div class="image-item">
              <img src="./static/images/datasample.png" alt="Sample 1" style="width: 100%; margin-top: 10px; margin-bottom: 10px;" />
            </div>
            <div class="image-item">
              <img src="./static/images/datasample2.png" alt="Sample 2" style="width: 100%; margin-top: 10px; margin-bottom: 10px;" />
            </div>
            <div class="image-item">
              <img src="./static/images/datasample3.png" alt="Sample 3" style="width: 100%; margin-top: 10px; margin-bottom: 10px;" />
            </div>
            <div class="image-item">
              <img src="./static/images/datasample4.png" alt="Sample 4" style="width: 100%; margin-top: 10px; margin-bottom: 10px;" />
            </div>
          </div>
        </div>
      </div>
      <h2 class="subtitle has-text-centered">
        Samples of tasks in OmniAlign-V dataset.
      </h2>
    </div>
  </div>
</section>

<!-- 添加自定义样式 -->
<!-- 添加自定义样式 -->
<style>
  /* Grid 布局 */
  .image-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr); /* 每行两个 */
    gap: 20px; /* 图片之间的间距 */
  }

  /* 避免裁剪，保持图片比例 */
  .image-item img {
    width: 100%; /* 宽度占满父容器 */
    height: auto; /* 高度自动调整，保持比例 */
    display: block; /* 防止底部出现空白间隙 */
    margin-top: 10px;
    margin-bottom: 10px;
  }
</style>
<!-- /Results -->

<!-- BibTeX -->
<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{mgllava,
        title={Towards Semantic Equivalence of Tokenization in Multimodal LLM},
        author={Zhao, Xiangyu and Li, Xiangtai and Duan, Haodong and Huang, Haian and Li, Yining and Chen, Kai and Yang, Hua},
        journal={arXiv preprint},
        year={2024}
    }</code></pre>
  </div>
</section> -->
<!-- /BibTeX -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. Thanks for their excellent work.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
