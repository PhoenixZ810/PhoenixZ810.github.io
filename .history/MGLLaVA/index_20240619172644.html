<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MG-LLaVA: Towards Multi-Granularity Visual Instruction Tuning">
  <meta name="keywords" content="Multimodal Learning, Multimodal Large Language Model, Visual Understanding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MG-LLaVA: Towards Multi-Granularity Visual Instruction Tuning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MG-LLaVA: Towards Multi-Granularity Visual Instruction Tuning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a> Xiangyu Zhao</a><sup>1,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://lxtgh.github.io">Xiangtai Li</a><sup>2,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://kennymckormick.github.io/">Haodong Duan</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://zhangzjn.github.io/">Haian Huang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://qianyuzqy.github.io/">Yining Li</a><sup>3</sup>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://github.com/ly015">Kai Chen</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://chenkai.site/">Hua Yang</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiaotong University</span>
            <span class="author-block"><sup>2</sup>S-Lab, Nanyang Technological University</span>
            <span class="author-block"><sup>3</sup>Shanghai AI Laboratory</span>
            <!-- <br>
            <span class="author-block"><sup>4</sup>Zhejiang University</span>
            <span class="author-block"><sup>5</sup>Shanghai Jiao Tong University</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Paper Link. -->
              <span class="link-block">
                <a href="TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/iuH5iqLk5VQ?si=O05IiRwnTiU73FZK"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper video. -->

<!-- <section class="hero is-small">
  <div class="columns is-centered has-text-centered"  style="margin-top: -10px; margin-bottom: 20px;">
    <div class="column is-three-fifths">
      <p class="title is-4">TL;DR: MotionBooth is a innovative framework designed for animating customized subjects with precise control over both object and camera movements.</p>
      <div class="publication-video">
        <iframe width="276" height="256" src="https://www.youtube.com/embed/iuH5iqLk5VQ?si=RJdz2CdxO_eUWrKR" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
      </div>
    </div>
  </div>
</section> -->

<section class="hero is-small">
  <div class="columns is-centered has-text-centered"  style="margin-top: -10px; margin-bottom: 20px;">
    <div class="column is-three-fifths">
      <!-- <p class="title is-4">TL;DR: MotionBooth is a innovative framework designed for animating customized subjects with precise control over both object and camera movements.</p> -->
      <!-- <h2 class="title is-3 is-centered">LGVI Framework</h2> -->
      <div class="publication-img">
        <img id="architecture" src="./static/images/teaser9.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
      </div>
    </div>
  </div>
</section>

<!-- /Paper video.   -->

<!-- Abstract. -->
<section class="hero is-light">
  <div class="container is-max-desktop ">
    <div class="columns is-centered has-text-centered" style="margin-top: 10px; margin-bottom: 0px;">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this work, we present MG-LLaVA, an innovative MLLM that enhances the model's visual processing capabilities by incorporating a multi-granularity vision flow, which includes low-resolution, high-resolution, and object-centric features. We propose the integration of an additional high-resolution visual encoder to capture fine-grained details, which are then fused with base visual features through a Conv-Gate fusion network. To further refine the model's object recognition abilities, we incorporate object-level features derived from bounding boxes identified by offline detectors. Being trained solely on publicly available multimodal data through instruction tuning, MG-LLaVA demonstrates exceptional perception skills. We instantiate MG-LLaVA with a wide variety of language encoders, ranging from 3.8B to 34B, to evaluate the model's performance comprehensively. 0Extensive evaluations across multiple benchmarks demonstrate that MG-LLaVA outperforms existing MLLMs of comparable parameter sizes, showcasing its remarkable efficacy. The models and code will be available soon.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- /Abstract. -->

<!-- Method. -->
<section class="section" style="margin-top:-50px; margin-bottom:-50px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3 is-centered">Framework</h2>
            <div class="publication-img">
              <img id="architecture" src="./static/images/framework7.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
            </div>
          </div>
        </div>
        <p>
          The illustration of MG-LLaVA. Top left: The overall framework of MG-LLaVA, which includes the Multi-Granularity Vision Flow module and a LLM. Right: Illustration of Multi-Granularity Vision Flow, which aims to extract multiple visual features and integrate disparate features to ensure seamless interaction. Botttom left: Structure of Conv-Gate Fusion module.
        </p>
    </div>
  </div>
</section>
<!-- Method  -->

<!-- Results -->

<!-- <section>
  <div class="container is-max-desktop" style="margin-top:-100px; margin-bottom:-50px;">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3 is-centered">Results Visualization</h2>
        </div>
      </div>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/result-comparison-both1.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/result-comparison-both2.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        MotionBooth compared with baseline models for motion-aware customized video generation.
      </h2>
    </div>
  </div>
</section> -->

<section>
  <div class="container is-max-desktop" style="margin-top:-50px; margin-bottom:-50px;">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="publication-img">
            <img id="architecture" src="./static/images/exim.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
          </div>
        </div>
      </div>
      <h2 class="subtitle has-text-centered">
        Comparison of MG-LLaVA with other method in image understanding.
      </h2>
    </div>
  </div>
</section>


<section>
  <div class="container is-max-desktop" style="margin-top:-50px; margin-bottom:-50px;">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="publication-img">
            <img id="architecture" src="./static/images/exvideo.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
          </div>
        </div>
      </div>
      <h2 class="subtitle has-text-centered">
        Comparison of MG-LLaVA with other method in video understanding.
      </h2>
    </div>
  </div>
</section>

<!-- <section>
  <div class="container is-max-desktop" style="margin-top:-50px; margin-bottom:-50px;">
    <div class="hero-body">
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/more-results1.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/more-results2.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/more-results3.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/more-results4.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/more-results5.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        More results of MotionBooth.
      </h2>
    </div>
  </div>
</section> -->

<!-- /Results -->

<!-- BibTeX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>article{wu2024motionbooth,
      title={MotionBooth: Motion-Aware Customized Text-to-Video Generation},
      author={Jianzong Wu and Xiangtai Li and Yanhong Zeng and Jiangning Zhang and Qianyu Zhou and Yining Li and Yunhai Tong and Kai Chen},
      journal={arXiv pre-print},
      year={2024},
    }</code></pre>
  </div>
</section>
<!-- /BibTeX -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. Thanks for their excellent work.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
